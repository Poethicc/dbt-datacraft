---
category: main
step: 5_full
sub_step: 
doc_status: empty_template
language: rus
---
# macro `full`

## Список используемых вспомогательных макросов

```dataview
TABLE 
category AS "Category", 
in_main_macro AS "In Main Macro",
doc_status AS "Doc Status"
FROM "dbt Package"
WHERE file.name != "README" AND contains(in_main_macro, "full")
SORT doc_status
```

## Описание

Макрос `full` предназначен для объединения данных пайплайна с `registry`-таблицами. В зависимости от пайплайна поведение макроса меняется.
## Применение

Имя dbt-модели (=имя файла в формате sql в папке models) должно соответствовать шаблону:
`full_{название_пайплайна}`.

Например, `full_events`.

Внутри этого файла вызывается макрос:

```sql
{{ etlcraft.full() }}
```
Над вызовом макроса в файле будет указана зависимость данных через `—depends_on`. То есть целиком содержимое файла выглядит, например, вот так:
```sql
-- depends_on: {{ ref('graph_qid') }}

-- depends_on: {{ ref('link_events') }}

-- depends_on: {{ ref('link_registry_appprofilematching') }}

-- depends_on: {{ ref('link_registry_utmhashregistry') }}

{{ etlcraft.full() }}
```
## Аргументы

Этот макрос принимает следующие аргументы:
 
1. `params` (по умолчанию: none)
2.  `disable_incremental` (по умолчанию: none)
3. `override_target_model_name` (по умолчанию: none)
4. `date_from` (по умолчанию: none)
5. `date_to` (по умолчанию: none)
6. `limit0` (по умолчанию: none)
7. `metadata` (по умолчанию: результат макроса `project_metadata()`)
## Функциональность

Глобально работу макроса можно разделить на несколько смысловых этапов:

1) подготовка
2) материализация
3) отбор возможных и существующих таблиц registry
4) создание основы запроса для каждого пайплайна
5) отбор полей pipeline_columns для каждого пайплайна 
6) последовательное обогащение основного запроса данными из таблиц пайплайна `registry`

**1) подготовка**

Сначала макрос считает имя модели - либо из передаваемого аргумента (  
`override_target_model_name`), либо из имени файла (`this.name`). При использовании аргумента `override_target_model_name` макрос работает так, как если бы находился в модели с именем, равным значению `override_target_model_name`.

Название модели, полученное тем или иным способом, разбивается на части по знаку нижнего подчёркивания. Например, название `full_events` разобьётся на 2 части, из этих частей макрос возьмёт в работу:

- пайплайн - `pipeline_name` → events

**2) материализация** 

Для каждого пайплайна в макросе задаётся своя материализация и своё поведение в начале, до присоединения registry-таблиц:

- для пайплайна `events`- материализация `table` и соединение данных из таблиц `link_events` + `graph_qid` + имеющихся таблиц пайплайна `registry`

- для пайплайна `datestat` - материализация `incremental` и соединение данных из таблицы `link_datestat` + имеющихся таблиц пайплайна `registry`

- для пайплайна `periodstat` - материализация `incremental` и разбиение метрик по дням + добавление имеющихся таблиц пайплайна `registry`

**3) отбор возможных и существующих таблиц пайплайна `registry`**

На этом этапе сначала в макросе создаётся список возможных таблиц пайплайна `registry` - это нужно для всех пайплайнов. Для создания такого списка макрос обращается к `metadata` (она передаётся через аргумент и по умолчанию `metadata` = результат макроса `project_metadata()`).

Далее макрос при помощи вспомогательного макроса [[clickhouse__check_table_exists]] будет отбирать те таблицы пайплайна `registry`, которые в действительности существуют.

**4) создание основы запроса для каждого пайплайна**

Для каждого пайплайна создаём основу будущего SQL-запроса. Оформляем это при помощи `common table expressions` - `CTE`.  Этот основной `CTE` для всех пайплайнов будет называться одинаково: `t0`.  К нему в дальнейшем будут добавляться `t1`, `t2` и т.д. в зависимости от количества имеющихся таблиц пайплайна `registry`.

Для каждого пайплайна основа данных - своя. Поэтому макрос начинает перебор пайплайнов с помощью оператора `if` и каждому задаёт свою основу основу будущего запроса - `t0`:

- **для пайплайна `events`** основа запроса это `link_events` + `graph_qid`:

```sql
WITH t0 AS (

SELECT * FROM {{ ref('link_events') }}

LEFT JOIN {{ ref('graph_qid') }} USING (__id, __link, __datetime)

)
```
- **для пайплайна `datestat`** это `link_datestat`:

```sql
WITH t0 AS (

SELECT * FROM {{ ref('link_datestat') }}

)
```
  
- **для пайплайна `periodstat`** поведение макроса более насыщенное: на этом этапе макрос берёт данные из `link_periodstat` и разбивает их по дням.

Чтобы осуществить это поведение, внутри макроса понадобится произвести дополнительные действия.

В макросе задаются наименования числовых типов данных:

```sql
{%- set numeric_types = ['UInt8', 'UInt16', 'UInt32', 'UInt64', 'UInt256',

                        'Int8', 'Int16', 'Int32', 'Int64', 'Int128', 'Int256',

                        'Float8', 'Float16','Float32', 'Float64','Float128', 'Float256','Num'] -%}
```
Затем задаются два списка - для колонок с числовыми и нечисловыми типами данных.

Далее макрос при помощи вспомогательного макроса [[get_columns_in_relation]] берёт все колонки, проверяет у каждой тип данных, и распределяет их по этим двум спискам.

Для этого пайплайна макрос не сразу создаёт `t0`, а сначала делает подготовительный шаг - `unnest_dates`. 

Здесь макрос разбивает период на дни. Например, в данных была одна строка с такими значениями:
- periodStart='2024-01-01'
- periodEnd='2024-01-31' 
- cost =31000 

Из этой одной строки макрос создаст 31 строку - по одной на каждый день этого периода и значением в новом столбце `cost_per_day` равным 1000. Вот как выглядит подготовительный шаг `unnest_dates`:
```sql
WITH unnest_dates AS (

SELECT *, {# берём все данные, какие были в таблице и добавляем к ним каждый день периода #}

    dateAdd(periodStart, arrayJoin(range( 0, 1 + toUInt16(date_diff('day', periodStart, periodEnd))))) AS period_date

    , COUNT(*) OVER(PARTITION BY

{% for c in columns_not_numeric -%}{{c}}

{% if not loop.last %},{% endif %}

{% endfor %}

    ) AS divide_by_days {# здесь мы вычисляем кол-во дней, на которое надо будет в дальнейшем делить метрики #}

FROM {{ ref('link_periodstat') }}

)
```
и после этого подготовительного шага уже создаётся `t0`. На этом шаге идёт отбор всех дат периода, нечисловые колонки идут в запрос SELECT в таком же виде, в каком они были изначально. А значения в числовых колонках делятся на количество дней в периоде. Таким образом для числовых данных образуются новые колонки, названия которых заканчиваются на `_per_day`. Например, была числовая колонка `cost`, а станет колонка `cost_per_day`. Вот как выглядит код этого шага:
```sql
, t0 AS (

SELECT period_date, {# отбираем все даты периода  #}

{% for column in columns_not_numeric -%}{{column}}, {# не числовые колонки - такими какими они и были #}

{% endfor %}   {# а значения в числовых колонках делим на количество дней в периоде #}

{% for column in columns_numeric -%}{{column}}/divide_by_days AS {{column}}_per_day {# и таким образом получаем новые столбцы #}

{% if not loop.last %},{% endif %}   {# например вместо cost будет cost_per_day #}

{% endfor %}

FROM unnest_dates

)
```
**5) отбор полей pipeline_columns для каждого пайплайна**
  
На этом шаге нет условия if, но, поскольку при вызове моделей у каждой свой pipeline_name, значения будут разными.

Макрос задаёт переменную `pipeline_columns`, в которую будет отбирать колонки с сущностями каждого пайплайна.

Далее на этом шаге макрос обращается к `metadata`, отбирает линки и получает все необходимые для дальнейшей работы данные по каждому нужному линку.

Ранее созданная переменная `pipeline_columns` заполняется теми сущностями (`entities`) из метадаты, которые соответствуют пайплайну модели и её линкам. Каждое название сущности дополняется окончанием `Hash`, и таким образом в этой переменной в процессе работы макроса оказывается уникальный список захэшированных названий колонок сущностей.

Например, для пайплайна `events` такой список (`pipeline_columns`) может выглядеть следующим образом:
```sql
'AccountHash', 'AppMetricaDeviceHash', 'MobileAdsIdHash', 'CrmUserHash', 'OsNameHash', 'CityHash', 'AdSourceHash', 'UtmParamsHash', 'UtmHashHash', 'TransactionHash', 'PromoCodeHash', 'AppSessionHash', 'VisitHash', 'YmClientHash'
```

  **6) последовательное обогащение основного запроса данными из таблиц пайплайна `registry`**

На этом шаге в макросе происходит цикл `for` для последовательных джойнов: основа запроса - `t0`- последовательно обогащается данными из таблиц пайплайна `registry` (автоматически создаются и добавляются `t1`, `t2`).

Чтобы джойны могли отработать, в макросе создаётся переменная `fields_list`. В неё будут отбираться поля для будущего `USING(...)` в блоке `JOIN`.

Макрос перебирает таблицы в ранее отобранном списке существующих таблиц пайплайна `registry` (см. шаг 3) отбор возможных и существующих таблиц пайплайна `registry`**)











{%- for r in registry_existing_tables -%}  

    {%- set fields_list = [] -%} {# создаём список, куда будем отбирать поля для будущего USING(...) #}

    {%- set links_list = [] -%}

    {%- set links = metadata['links'] -%}

    {%- for link in links  -%}

      {%- if link|lower == r.split('_')[-1]  -%} {# приводим к нижнему регистру и сравниваем с линком из названия модели #}

        {%- do links_list.append(link) -%} {# если они совпадают, отбираем этот линк #}

      {%- endif -%}

    {%- endfor -%}

    {#- для этого линка отбираем связанные с ним сущности -#}

    {%- for link_name in links_list  -%}

        {%- set main_entities = links[link_name].get('main_entities') or [] -%}

                                  {#-  {%- set other_entities = links[link_name].get('other_entities') or [] -%} -#}

                                  {#-  {%- set entities = main_entities + other_entities -%} -#}

        {%- for entity in main_entities -%}

            {%- do fields_list.append(entity ~ 'Hash') -%} {# сохраняем имя поля с этой сущностью для будущего USING(...) #}

        {%- endfor -%}

    {%- endfor -%}

    {#- делаем полученный список уникальным -#}

    {%- set fields_list = fields_list|unique|list -%}

  

    {#- отбираем только те значения fields_list, которые есть в pipeline_columns -#}

    {%- set existing_fields_list = [] -%}

    {%- for f in fields_list -%}

        {%- if f in pipeline_columns|unique|list -%}

            {%- do existing_fields_list.append(f) -%}

        {%- endif -%}

    {%- endfor -%}

  

    {# здесь проходим циклом - создаём t1, который обогащает t0 одной таблицей registry,

    на следующем обороте t2 обогащает t1 ещё одной таблицей registry и тд.

    Для каждого раза у нас автоматически подставляются и таблица registry, и её хэш-поля в USING(...) для верного джойна #}

  

{%- if existing_fields_list|length >= 1 -%} {# если у нас есть общие поля, по к-ым можно сделать USING(...), то мы делаем джойн #}

, t{{loop.index}} AS (

SELECT t{{loop.index-1}}.*, {{r}}.*EXCEPT(__emitted_at, __table_name, __id, __datetime, __link)

FROM t{{loop.index-1}}

LEFT JOIN {{r}} USING ({% for f in existing_fields_list %}{{f}}{% if not loop.last %},{% endif -%}{% endfor %})

)

{%- else -%}   {# если общих полей для USING(...) нет, то мы этот шаг делаем без джойна, просто как SELECT * FROM предыдущий шаг #}

, t{{loop.index}} AS (

SELECT *

FROM t{{loop.index-1}}

)

{%- endif -%}

  

{%- endfor %} {# после завершения цикла берём t<кол-во имевшихся registry-таблиц> - т.е. из последнего CTE #}

SELECT COLUMNS('^[^.]+$') FROM t{{registry_existing_tables|length}}

{% if limit0 %}

LIMIT 0

{%- endif -%}

  

{#- SELECT COLUMNS('^[a-z|_][^2]')  помогало отбирать на лету все колонки по regexp - например все колонки кроме t2.<...>  -#}

{#- SELECT COLUMNS('^[a-zA-z|_|0-9]*$') FROM отобрать все колонки, кроме тех, где есть точка

то есть от начала до конца есть только буквы, цифры, нижние подчеркивания -#}

  

{% endmacro %}

## Пример

Файл в формате sql в папке models. Название файла `full_events`

Содержимое файла:
```sql
-- depends_on: {{ ref('graph_qid') }}

-- depends_on: {{ ref('link_events') }}

-- depends_on: {{ ref('link_registry_appprofilematching') }}

-- depends_on: {{ ref('link_registry_utmhashregistry') }}

{{ etlcraft.full() }}
```

## Примечания

Это восьмой из основных макросов.